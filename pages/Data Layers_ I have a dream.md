title:: Data Layers: I have a dream

-
- [Slide]( https://docs.google.com/presentation/d/1EoyjA923gq4gvHmIW3Kcp7UQ519hrflw4CeCRDR1EE0/edit?usp=sharing)
-
- 现状
	- Table Trait
	- Engine
		- Fuse (file based)
		- Github
		- Memory
	- Stream Source
		- CSV
		- Parquet
		- Value
- 用户故事
	- 将 X 存储上的 Y 数据导入到 Databend
	- X = s3/gcs/oss
	- Y = avro/parquet/csv/orc
- 想法
	- Features
		- CDC: change data capture
			- HTTP Webhook
			- Database CDC
		- Scheduled data fetch
			- Load from source per hours?
		- Query Pushdown
			- S3 Selcet
			- Big Query?
		- Online ETL
	- Data Connector
		- format: [[Avro]], [[Parquet]], [[CSV]], httpd/nginx log, mysql dump files
		- storage: fs/[[nfs]]/nas/[[s3]]/[[gcs]]/oss/[[ipfs]] -> DAL
- 规划
	- DAL2
		- Init String
		-
	- Cloud Native Storage Format
	- ```sql
	  copy into default.test from '@stage' format parquet;
	  ```
	-
- 现在的进展
	- DAL2 refactor
		- implement s3 support
- 参考资料
	- [Prestodb Connectors](https://prestodb.io/docs/current/connector.html)
	- [[Apache Flink/Connectors]]
	- [Snowpipe](https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro.html)
-